{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/raymondyuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Download any necessary nltk files for nlp\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Articles.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article      Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  1/1/2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  1/2/2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  1/5/2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  1/6/2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  1/6/2015   \n",
       "\n",
       "                                             Heading  NewsType  \n",
       "0  sindh govt decides to cut public transport far...  business  \n",
       "1                    asia stocks up in new year trad  business  \n",
       "2           hong kong stocks open 0.66 percent lower  business  \n",
       "3             asian stocks sink euro near nine year   business  \n",
       "4                 us oil prices slip below 50 a barr  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2692,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Article'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex to remove all Non-Alpha Numeric \n",
    "SPECIAL_CHARS = re.compile(r'([^a-z\\d!?.\\s])', re.IGNORECASE)\n",
    "\n",
    "def read_texts(path_file):\n",
    "    label = int(\"invalid\" not in path_file)\n",
    "    texts = np.load(path_file)['text']\n",
    "    labels = [label] * len(texts)\n",
    "    filter_texts = [SPECIAL_CHARS.sub('',  t) for t in texts]\n",
    "    return filter_texts, labels\n",
    "\n",
    "# Get all training data\n",
    "train_pos_data = read_texts(\"/Users/raymondyuan/Google Drive/Rice/Year 4/COMP 413/code/DatelineRice2.0-NLP/valid_texts_1189.npz\")\n",
    "train_neg_data = read_texts(\"/Users/raymondyuan/Google Drive/Rice/Year 4/COMP 413/code/DatelineRice2.0-NLP/invalid_texts.npz\")\n",
    "\n",
    "train_texts = train_pos_data[0] + train_neg_data[0]\n",
    "train_labels = train_pos_data[1] + train_neg_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_invalid = data['Article'].values\n",
    "train_texts.extend(external_invalid)\n",
    "train_labels.extend([0] * len(external_invalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 3537\n",
      "Number of validation examples 394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples {len(train_texts)}\")\n",
    "print(f\"Number of validation examples {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=word_tokenize,\n",
    "                      min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "                      smooth_idf=1, sublinear_tf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Vectorizer TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=1,\n",
      "        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=<function word_tokenize at 0x1a13a0d268>, use_idf=1,\n",
      "        vocabulary=None)\n",
      "Fitting to all docs...\n",
      "Transforming train docs...\n",
      "Transforming val docs...\n"
     ]
    }
   ],
   "source": [
    "print(\"Created Vectorizer %s\" % vec)\n",
    "print(\"Fitting to all docs...\")\n",
    "vec.fit(train_texts + val_texts)\n",
    "print(\"Transforming train docs...\")\n",
    "trn_term_doc = vec.transform(train_texts)\n",
    "print(\"Transforming val docs...\")\n",
    "val_term_doc = vec.transform(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual='auto', verbose=0):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.verbose = verbose\n",
    "        self._clf = None\n",
    "        print(\"Creating model with C=%s\" % C)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.score(x.multiply(self._r), y)\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y == y_i].sum(0)\n",
    "            return (p + 1) / ((y == y_i).sum() + 1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x, 1, y) / pr(x, 0, y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        if self.dual == 'auto':\n",
    "            self.dual = x_nb.shape[0] <= x_nb.shape[1]\n",
    "        self._clf = LinearSVC(C=self.C, dual=self.dual, verbose=self.verbose)\n",
    "        self._clf.fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with C=0.01\n",
      "Creating model with C=0.01\n",
      "Model had val score of 0.9720812182741116\n",
      "New maximum score improved from -inf to 0.9720812182741116\n",
      "Fitting with C=0.1\n",
      "Creating model with C=0.1\n",
      "Model had val score of 0.9771573604060914\n",
      "New maximum score improved from 0.9720812182741116 to 0.9771573604060914\n",
      "Fitting with C=1.0\n",
      "Creating model with C=1.0\n",
      "Model had val score of 0.9847715736040609\n",
      "New maximum score improved from 0.9771573604060914 to 0.9847715736040609\n",
      "Fitting with C=10.0\n",
      "Creating model with C=10.0\n",
      "Model had val score of 0.9898477157360406\n",
      "New maximum score improved from 0.9847715736040609 to 0.9898477157360406\n",
      "Fitting with C=100.0\n",
      "Creating model with C=100.0\n",
      "Model had val score of 0.9898477157360406\n",
      "Best score with C=10.0 is 0.9898477157360406\n"
     ]
    }
   ],
   "source": [
    "# Search for the appropriate C\n",
    "Cs = [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "\n",
    "best_model = None\n",
    "best_val = -float(\"inf\")\n",
    "best_C = None\n",
    "for C in Cs:\n",
    "    print(\"Fitting with C={}\".format(C))\n",
    "    model = NbSvmClassifier(C=C, verbose=0).fit(trn_term_doc, train_labels)\n",
    "    # Evaluate the model\n",
    "    val_preds = model.predict(val_term_doc)\n",
    "    score = np.mean(val_labels == val_preds)\n",
    "\n",
    "    print(\"Model had val score of %s\" % score)\n",
    "    if score > best_val:\n",
    "        print(\"New maximum score improved from {} to {}\".format(best_val, score))\n",
    "        best_model = model\n",
    "        best_val = score\n",
    "        best_C = C\n",
    "score = best_val\n",
    "print(\"Best score with C={} is {}\".format(best_C, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898477157360406"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(val_term_doc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= read_texts(\"/Users/raymondyuan/Google Drive/Rice/Year 4/COMP 413/code/DatelineRice2.0-NLP/valid_texts1198.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(set(test[0]) - set(train_texts + val_texts))\n",
    "test_labels = [1] * len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(vec.transform(test), test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
